llama2_7B_45B_sparse50_LR2e-4_GC2_E2_70_LR2e-4_E2_GC2_Tdense_LR1e-4_E1: 
  prompt_template: "zephyr-7b-alpha/prompt.txt"
  fn_completions: "sparseml_local_completions"
  completions_kwargs:
    model_name: "/network/alexandre/research/cerebras/llama2_7B_45B_sparse50_LR2e-4_GC2_E2_70_LR2e-4_E2_GC2_Tdense_LR1e-4_E1/training"
    model_kwargs:
      torch_dtype: 'bfloat16'
    max_new_tokens: 2048
    temperature: 0.6
    top_p: 0.9
    do_sample: True
  pretty_name: "Llama2 7b finetuned on ultrachat 200k"
