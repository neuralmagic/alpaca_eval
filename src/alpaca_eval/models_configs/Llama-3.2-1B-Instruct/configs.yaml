Llama-3.2-1B-Instruct:
  completions_kwargs:
    do_sample: true
    max_new_tokens: 4096
    model_kwargs:
      dtype: bfloat16
      enable_chunked_prefill: True
    model_name: meta-llama/Llama-3.2-1b_instruct
    stop_token_ids:
    - 128001
    - 128008
    - 128009
    temperature: 0.6
    top_p: 0.9
  fn_completions: vllm_local_completions
  pretty_name: Llama-3.2-1B-Instruct
  prompt_template: Llama-3.2-1B-Instruct/prompt.txt
